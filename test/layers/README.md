# Layer Testing

To run a layer test, use the `run_test.sh` script using the following arguments:

```
run_test.sh [-l (layer)] [-n (test number)] [-c,-s,-e,-i]
```

The final flags correspond to the following:
 - `-c` = C simulation
 - `-s` = Synthesis
 - `-e` = Co-simulation
 - `-i` = Implementation

To run c-simulation for the 0th test of the __convolution__ layer for example, you would run `./run_test.sh -l convolution -n 0 -c`.

For more details on what the `run_test.sh` script is calling, look at the `scripts/run_hls.tcl` script, which Vivado HLS calls.

The general file structure for each module test is as follows:

```bash
module/
├── config
│   └── config_n.json     # file containing parameters for test n
├── data
│   └── test_n            # data generated by gen_data.py script for the HLS testbench
│       ├── input.dat
│       └── output.dat
├── layer_hls_prj/
├── gen_data.py           # generates data.yaml file from config_n.json
├── rpt
│   └── test_n.json       # a report generated which gives usage and performance for module
├── include
│   └── layer.hpp         # generated header file for the layer instance
├── src
│   ├── layer.cpp         # generated source file for the layer instance
│   └── layer_top.cpp     # where the DUT is instantiated
└── tb
    ├── layer_tb.cpp      # layer testbench
    └── layer_tb.hpp      # layer file for DUT and testbench
```

For each layer, a functional model is needed to generate reference test data. These models can be found in the `models/layers/` folder of the fpgaconvnet-optimiser repository. The `gen_data.py` script calls this model for the given parameters.

The data is then loaded into the testbench using the `load_data` function from the `include/common_tb.cpp` folder. This function is overloaded for data of different dimensionality. This is then converted to a hls stream using the `to_stream` function.

